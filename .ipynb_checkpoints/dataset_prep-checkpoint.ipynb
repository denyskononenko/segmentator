{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from matplotlib.image import imsave\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TRAININGSET = \"/Users/denyskononenko/Documents/build_proc/images/training/building_facade/\"\n",
    "PATH_TO_TRAININGSET_2 = \"/Users/denyskononenko/Documents/build_proc/images/training/building_complex/\"\n",
    "# directory with processed buildings mask and init images \n",
    "PATH_TO_BUILDINGS_TRAININSET = \"/Users/denyskononenko/Documents/build_proc/images/training/building_facade_buildings/\"\n",
    "\n",
    "# masks of init rgb image and segmented png mask\n",
    "INIT_PATTERN = \"ADE_train_xxxxxxxx.jpg\"\n",
    "MASK_PATTERN = \"ADE_train_xxxxxxxx_seg.png\"\n",
    "\n",
    "BUILDING_PIXEL = [10, 56]\n",
    "HOUSE_PIXEL = [40, 252]\n",
    "SKYSCKRAPPER_PIXEL = [90, 119]\n",
    "\n",
    "image_masks = [f for f in glob.glob(PATH_TO_TRAININGSET + \"*.png\")]\n",
    "images = [f for f in glob.glob(PATH_TO_TRAININGSET + \"*.jpg\")]\n",
    "\n",
    "# get id of RGB images from training set \n",
    "image_id = [re.search(r\"train_(.+?).jpg\", file.split(\"/\")[-1]).group(1) for file in images]\n",
    "\n",
    "# get actual ids from trainingset \n",
    "os.chdir(PATH_TO_BUILDINGS_TRAININSET)\n",
    "image_ids = os.listdir()\n",
    "#image_ids = [re.search(r\"train_(.+?).jpg\", file.split(\"/\")[-1]).group(1) for file in images]\n",
    "#image_ids.remove(\".DS_Store\")\n",
    "#print(image_ids)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Generator of data class for u-net neural network \n",
    "    Images are obteined from the ADE20K dataset http://sceneparsing.csail.mit.edu/\n",
    "    \n",
    "    Structure of trainig dataset:\n",
    "    image id = xxxxxxxx\n",
    "    rgb initial image \"ADE_train_id.jpg\"\n",
    "    segmented image \"ADE_train_id.jpg\"\n",
    "    Object class category is coded by the r, g channels of the each pixel. For building [10, 56, *], for house [40, 252]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ids, path, batch_size=8, image_size=128):\n",
    "        self.ids = ids\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def _load_image_mask_pair(self, image_id):\n",
    "        \"\"\"\n",
    "        Load image and its mask\n",
    "        @param image_id image id form self.ids\n",
    "        \"\"\"\n",
    "        image = DataGenerator.read_img(self.path + \"/{}/\".format(image_id) + \"img_{}.png\".format(image_id))\n",
    "        mask = DataGenerator.read_img(self.path + \"/{}/\".format(image_id) + \"mask_{}.png\".format(image_id))\n",
    "        \n",
    "        \n",
    "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        mask = cv2.resize(mask, (self.image_size, self.image_size))\n",
    "        \n",
    "        return image[:,:,:3]/255.0, mask[:,:,:1]/255.0\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        images = []\n",
    "        masks = []\n",
    "        \n",
    "        batch_indices = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        \n",
    "        for img_id in batch_indices:\n",
    "            img, mask = self._load_image_mask_pair(img_id)\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "        \n",
    "        return np.array(images), np.array(masks)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids)/float(self.batch_size)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_img(img_path):\n",
    "        \"\"\"\n",
    "        Read image from the img_path (URL or file). \n",
    "        Returns numpy array.\n",
    "        \"\"\"\n",
    "        img = imread(img_path)\n",
    "        return img\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_path_by_id(img_id):\n",
    "        \"\"\"\n",
    "        Generate path to the image and its segmented variant by id\n",
    "        @param img_id id of the image\n",
    "        @return {\"init_image\": name, \"segments\": segmented image name}\n",
    "        \"\"\"\n",
    "        return {\"init_image\": re.sub(r\"xxxxxxxx\", str(img_id), INIT_PATTERN), \"segments\": re.sub(r\"xxxxxxxx\", str(img_id), MASK_PATTERN)}\n",
    "    \n",
    "    @staticmethod\n",
    "    def show_img_mask(img, mask, image_size=128):\n",
    "        \"\"\"\n",
    "        Display image and mask.\n",
    "        @param img in the form of numpy array \n",
    "        @param mask in the form of numpy array \n",
    "        @param image_size size of image\n",
    "        \"\"\"\n",
    "        plt.tight_layout(pad=0.5, w_pad=10.0, h_pad=0.5) # minimize overlapping of subplots\n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.subplot(131)\n",
    "        plt.title(\"Image\", fontsize=18)\n",
    "        plt.imshow(img)\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.title(\"Mask\", fontsize=18)\n",
    "        plt.imshow(np.reshape(mask, (image_size, image_size)), cmap=\"gray\")\n",
    "       \n",
    "        # show mask and iamge overlapping \n",
    "        plt.subplot(133)\n",
    "        plt.title(\"Overlapping\", fontsize=18)\n",
    "        plt.imshow(np.reshape(mask, (image_size, image_size)), cmap=\"gray\")\n",
    "        plt.imshow(img, cmap=\"jet\", alpha=0.5) \n",
    "        \n",
    "    \n",
    "    @staticmethod \n",
    "    def display_valid_imgs(img, background, result, image_size=128):\n",
    "        \"\"\"\n",
    "        Display init image, background truth and prediction of NN\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        \n",
    "        plt.subplot(131)\n",
    "        plt.title(\"init image\", fontsize=18)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        plt.subplot(132)\n",
    "        plt.title(\"Background truth\", fontsize=18)\n",
    "        plt.imshow(np.reshape(background, (image_size, image_size)), cmap=\"gray\")\n",
    "        \n",
    "        plt.subplot(133)\n",
    "        plt.title(\"Background truth\", fontsize=18)\n",
    "        plt.imshow(np.reshape(result, (image_size, image_size)), cmap=\"gray\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def show_imgs(img1, img2, img3, img_id):\n",
    "        \"\"\"\n",
    "        Dispaly an image pairt.\n",
    "        @param img1 url or numpy array for image #1\n",
    "        @param img2 url or numpy array for image #2\n",
    "        @param img3 url or numpy array for image #3 \n",
    "        \"\"\"\n",
    "        if type(img1) == str and type(img2) == str and type(img3) == str:\n",
    "            # case of link on the image\n",
    "            imarr_1 = DataGenerator.read_img(img1)\n",
    "            imarr_2 = DataGenerator.read_img(img2)\n",
    "            imarr_3 = DataGenerator.read_img(img3)\n",
    "            name1 = img1.split(\"/\")[-1]\n",
    "            name2 = img2.split(\"/\")[-1]\n",
    "            name3 = img2.split(\"/\")[-1]\n",
    "        else:\n",
    "            # case of numpy array \n",
    "            imarr_1 = img1\n",
    "            imarr_2 = img2\n",
    "            imarr_3 = img3\n",
    "            name1 = str(img_id)\n",
    "            name2 = \"Segmented\"\n",
    "            name3 = \"Mask\"\n",
    "        \n",
    "        plt.tight_layout(pad=0.5, w_pad=10.0, h_pad=0.5) # minimize overlapping of subplots\n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.subplot(131)\n",
    "        plt.title(\"Image 1 \\nid: {}\".format(name1), fontsize=18)\n",
    "        plt.imshow(imarr_1)\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.title(\"Image 2 \\nname: {}\".format(name2), fontsize=18)\n",
    "        plt.imshow(imarr_2)\n",
    "        \n",
    "        plt.subplot(133)\n",
    "        plt.title(\"Image 3 \\nname: {}\".format(name3), fontsize=18)\n",
    "        plt.imshow(imarr_3, cmap=\"gray\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mask(img, image_size=128):\n",
    "        \"\"\"\n",
    "        Detect particular class mask.\n",
    "        @param img url of image or its numpy array\n",
    "        @param image_size size of image\n",
    "        @return mask geayscale image with seleced mask of appropriate mask object\n",
    "        \"\"\"\n",
    "        building_pixels = [] # pixels of building class\n",
    "        if type(img) == str:\n",
    "            mask = DataGenerator.read_img(img)\n",
    "        else:\n",
    "            mask = img\n",
    "        # get pixels, unique pixels and its grayscale variants of mask\n",
    "        pixels = np.reshape(mask, (mask.shape[0] * mask.shape[1], 3))\n",
    "        unique_pixels = np.unique(pixels, axis=0)\n",
    "        gray_unique_pixels = cv2.cvtColor(np.array([unique_pixels]), cv2.COLOR_BGR2GRAY)\n",
    "        # check presence of buildings related to the building class\n",
    "        for pixel in unique_pixels:\n",
    "            if pixel[0] == BUILDING_PIXEL[0] and pixel[1] == BUILDING_PIXEL[1] or pixel[0] == HOUSE_PIXEL[0] and pixel[1] == HOUSE_PIXEL[1] or pixel[0] == SKYSCKRAPPER_PIXEL[0] and pixel[1] == SKYSCKRAPPER_PIXEL[1]:\n",
    "                building_pixels.append(pixel) \n",
    "        # grayscale of buildig class pixels\n",
    "        gray_building_pixels = cv2.cvtColor(np.array([building_pixels]), cv2.COLOR_BGR2GRAY)[0]\n",
    "        #print(gray_building_pixels)\n",
    "        \n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        init_mask = np.copy(mask)\n",
    "        mask = (init_mask == gray_building_pixels[0])*1.0\n",
    "        if len(gray_building_pixels) > 1:\n",
    "            for pixel in gray_building_pixels[1:]:\n",
    "                mask += (init_mask == pixel)*1.0\n",
    "        mask = cv2.resize(mask, (image_size, image_size)) \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_img_mask_pair(id_arr, image_size):\n",
    "        \"\"\"\n",
    "        @param id_arr array of images id\n",
    "        @param image_size size of image\n",
    "        \"\"\"\n",
    "        for imd in id_arr:\n",
    "            image = DataGenerator.read_img(PATH_TO_TRAININGSET + DataGenerator.make_path_by_id(imd)[\"init_image\"])\n",
    "            image_name = \"img_{}.png\".format(imd)\n",
    "            if image.shape != (self.image_size, self.image_size, 3):\n",
    "                image = cv2.resize(image, (image_size, image_size))\n",
    "\n",
    "            segmented_image = DataGenerator.read_img(PATH_TO_TRAININGSET + DataGenerator.make_path_by_id(imd)[\"segments\"])\n",
    "            mask = DataGenerator.get_mask(segmented_image)\n",
    "            mask_name = \"mask_{}.png\".format(imd)\n",
    "            #save images and masks in separate directory\n",
    "            os.chdir(PATH_TO_BUILDINGS_TRAININSET)\n",
    "            os.mkdir(str(imd))\n",
    "            imsave(PATH_TO_BUILDINGS_TRAININSET + \"/{}/\".format(str(imd)) + image_name, image)\n",
    "            imsave(PATH_TO_BUILDINGS_TRAININSET + \"/{}/\".format(str(imd)) + mask_name, mask, cmap=\"gray\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_labelbox_json(path):\n",
    "        \"\"\"\n",
    "        Select image mask urls dic from labelbox array.\n",
    "        @param path to the labelbox data\n",
    "        @return list of dictionaries of label--mask pair urls \n",
    "        \"\"\"\n",
    "        res  = []\n",
    "        f = open(path, \"r\", encoding=\"utf-8\")\n",
    "        data = json.load(f)\n",
    "        \n",
    "        for item in data:\n",
    "            temp = {}\n",
    "            if \"Masks\" in item:\n",
    "                temp[\"image\"] = item[\"Labeled Data\"]\n",
    "                temp[\"mask\"] = item[\"Masks\"][\"building\"]\n",
    "                res.append(temp)\n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def download_labelbox_data(label_box_data, image_size=128):\n",
    "        \"\"\"\n",
    "        Method for uploading labelbox mask image pairs and appending \n",
    "        them to the existing dataset with preservation of current directories nonation \n",
    "        @param path path to the trainingset\n",
    "        \"\"\"\n",
    "        path = PATH_TO_BUILDINGS_TRAININSET\n",
    "        os.chdir(path)\n",
    "        dir_list = [int(x) for x in os.listdir()]\n",
    "        dir_list.sort()\n",
    "        \n",
    "        last_id = dir_list[-1]\n",
    "        last_dir_name = \"0000\" + str(last_id)\n",
    "        \n",
    "        for item in label_box_data:\n",
    "            # download and resize data\n",
    "            img = DataGenerator.read_img(item[\"image\"]) \n",
    "            mask = DataGenerator.read_img(item[\"mask\"])\n",
    "            mask = cv2.cvtColor(mask[:,:,:3], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img = cv2.resize(img, (image_size, image_size))\n",
    "            mask = cv2.resize(mask, (image_size, image_size))\n",
    "            \n",
    "            \n",
    "            # make new id\n",
    "            last_id += 1 \n",
    "            last_dir_name = \"0005\" + str(last_id)\n",
    "            \n",
    "            image_name = \"img_{}.png\".format(last_dir_name)\n",
    "            mask_name = \"mask_{}.png\".format(last_dir_name)\n",
    "            \n",
    "            print(last_dir_name)\n",
    "            print(image_name)\n",
    "            print(mask_name)\n",
    "            #save images and masks in separate directory\n",
    "            os.chdir(PATH_TO_BUILDINGS_TRAININSET) \n",
    "            os.mkdir(last_dir_name)\n",
    "            imsave(PATH_TO_BUILDINGS_TRAININSET + \"/{}/\".format(last_dir_name) + image_name, img)\n",
    "            imsave(PATH_TO_BUILDINGS_TRAININSET + \"/{}/\".format(last_dir_name) + mask_name, mask, cmap=\"gray\")\n",
    "\n",
    "            #DataGenerator.show_img_mask(img, mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelbox_data = \"/Users/denyskononenko/Documents/build_proc/label_box_data/export-2019-07-18.json\"\n",
    "#data = DataGenerator.parse_labelbox_json(labelbox_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = data[1]\n",
    "#print(test_data[\"image\"])\n",
    "#print(test_data[\"mask\"])\n",
    "#DataGenerator.download_labelbox_data(data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataGenerator.make_img_mask_pair(image_id)\n",
    "data_gen = DataGenerator(image_ids, PATH_TO_BUILDINGS_TRAININSET)\n",
    "x, y = data_gen.__getitem__(3)\n",
    "#print(x.shape, y.shape)\n",
    "\n",
    "DataGenerator.show_img_mask(x[0], y[0])\n",
    "#print(x[0])\n",
    "#testim = DataGenerator.read_img(PATH_TO_BUILDINGS_TRAININSET + \"/{}/\".format(str(image_ids[0])) + \"mask_{}.png\".format(image_ids[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(len(image_id))\n",
    "#for imd in image_id[20:40]:\n",
    "#    image = DataGenerator.read_img(PATH_TO_TRAININGSET + DataGenerator.make_path_by_id(imd)[\"init_image\"]) \n",
    "#    segmented_image = DataGenerator.read_img(PATH_TO_TRAININGSET + DataGenerator.make_path_by_id(imd)[\"segments\"])\n",
    "#    mask = DataGenerator.get_mask(segmented_image)\n",
    "#    DataGenerator.show_img_pair(image, segmented_image, mask, imd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def test_dataset(testid):\n",
    "    building_pixels = []\n",
    "    nm = DataGenerator.read_img(PATH_TO_TRAININGSET_2 + DataGenerator.make_path_by_id(testid)[\"segments\"])\n",
    "\n",
    "    pixels = np.reshape(nm, (nm.shape[0] * nm.shape[1], 3))\n",
    "    unique_pixels = np.unique(pixels, axis=0)\n",
    "    gray_unique_pixels = cv2.cvtColor(np.array([unique_pixels]), cv2.COLOR_BGR2GRAY)\n",
    "    # check presence of buildings related to the building class\n",
    "    for pixel in unique_pixels:\n",
    "        if pixel[0] == 10 and pixel[1] == 56 or pixel[0] == 40 and pixel[1] == 252 or pixel[0] == 90 and pixel[1] == 119:\n",
    "            building_pixels.append(pixel)\n",
    "\n",
    "    print(unique_pixels) \n",
    "    print(gray_unique_pixels)\n",
    "\n",
    "\n",
    "    gray_building_pixels = cv2.cvtColor(np.array([building_pixels]), cv2.COLOR_BGR2GRAY)[0]\n",
    "    print(gray_building_pixels)\n",
    "    mask = (nm == [10, 56, 51])*1.0\n",
    "    for pixel in building_pixels:\n",
    "        mask += (nm == pixel)*1.0\n",
    "    print(mask.shape)\n",
    "\n",
    "    gray = cv2.cvtColor(nm, cv2.COLOR_BGR2GRAY)\n",
    "    init_gray = cv2.cvtColor(nm, cv2.COLOR_BGR2GRAY)\n",
    "    #gray = (mask == [0, 0, 0])*1.0 \n",
    "    gray = (init_gray == gray_building_pixels[0])*1.0\n",
    "    for gray_pix in gray_building_pixels[1:]:\n",
    "        print(gray_pix)\n",
    "        gray += (init_gray == gray_pix)*1.0\n",
    "    print(len(gray_building_pixels))\n",
    "\n",
    "    gray = cv2.resize(gray, (256, 256)) \n",
    "    print(np.amax(gray))\n",
    "    print(np.amax(gray.shape))\n",
    "    DataGenerator.show_imgs(nm, mask, gray, testid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_id = [\"00004591\", \"00004688\", \"00004598\", \"00004750\", \"00004605\", \"00004731\"]\n",
    "#test_dataset(test_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
